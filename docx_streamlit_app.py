
import streamlit as st
from docx import Document
import pandas as pd
import re
import json
from typing import Dict, List, Tuple
from st_diff_viewer import diff_viewer
import difflib
from pathlib import Path

def generate_medical_tree_html_universal(data_json, output_file="drzewo_programu.html"):
    if isinstance(data_json, str):
        try:
            data = json.loads(data_json)
        except:
            data = data_json
    else:
        data = data_json

    html = """<!DOCTYPE html>
<html lang="pl">
<head>
  <meta charset="UTF-8" />
  <title>ü©∫ Drzewo kwalifikacji ‚Äì Program lekowy</title>
  <style>
    body { font-family: 'Segoe UI', sans-serif; margin: 30px; background: #f9f9f9; color: #333; }
    details { margin-left: 20px; border-left: 2px solid #007acc; padding-left: 15px; }
    summary { font-weight: bold; cursor: pointer; font-size: 1.1em; color: #007acc; margin-top: 10px; }
    ul { margin-top: 5px; margin-bottom: 10px; }
    li { margin: 4px 0; }
    .section-title { font-weight: bold; color: #2c3e50; }
  </style>
</head>
<body>
  <h1>ü©∫ Drzewo kwalifikacji ‚Äì Program lekowy</h1>
  <p><strong>Instrukcja:</strong> Klikaj w strza≈Çki, by rozwijaƒá sekcje.</p>
"""

    section_titles = {
        "diagnosis": "ü©∫ Diagnoza",
        "age_requirements": "üìÖ Wymagania wiekowe",
        "eligibility_general": "‚úÖ Og√≥lne kryteria kwalifikacji",
        "eligibility_detailed": "üîç Szczeg√≥≈Çowe kryteria",
        "treatment_rules": "üìú Zasady stosowania",
        "treatment_duration": "‚è±Ô∏è Czas trwania leczenia",
        "discontinuation_criteria": "üõë Kryteria wy≈ÇƒÖczenia"
    }

    for key, title in section_titles.items():
        if key in data and data[key]:
            items = data[key]
            if isinstance(items, list):
                html += f"""  <details open>
    <summary class="section-title">{title}</summary>
    <ul>
"""
                for item in items:
                    html += f"      <li>{item.strip(' .;')}</li>\n"
                html += "    </ul>\n  </details>\n"
            elif isinstance(items, str) and items.strip():
                html += f"""  <details open>
    <summary class="section-title">{title}</summary>
    <p>{items.strip()}</p>
  </details>\n"""
            elif isinstance(items, dict):
                html += f"""  <details open>
    <summary class="section-title">{title}</summary>
"""
                for subkey, subitems in items.items():
                    subname = "Chemioterapia i leczenie celowane" if "chemo" in subkey else "Immunoterapia"
                    html += f"    <details><summary>{subname}</summary><ul>\n"
                    for drug in subitems:
                        html += f"      <li>{drug}</li>\n"
                    html += "    </ul></details>\n"
                html += "  </details>\n"

    html += """
  <p style="margin-top: 30px; font-size: 0.9em; color: #666;">
    Wygenerowano automatycznie.
  </p>
</body>
</html>"""

    with open(output_file, "w", encoding="utf-8") as f:
        f.write(html)

    print(f"‚úÖ Wygenerowano: {output_file}")
    return html

def parse_medical_program_v2(text: str) -> dict:
    """
    Zaawansowany parser, kt√≥ry najpierw dzieli tekst na sekcje, potem je analizuje.
    Dzia≈Ça na RJG, hepatologiƒô, itp.
    """
    # Normalizacja
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\[.*?\]\(.*?\)', '', text)
    text = text.replace(';', '. ')  # zastƒÖp ≈õredniki kropkami dla lepszego podzia≈Çu

    # Podzia≈Ç na sekcje po nag≈Ç√≥wkach
    sections = {}
    current_section = "start"
    sections[current_section] = []

    # Wzorce nag≈Ç√≥wk√≥w
    patterns = [
        (r'I\.\s+w\s+zakresie', 'chemotherapy_targeted'),
        (r'II\.\s+w\s+zakresie', 'immunotherapy'),
        (r'W\s+leczeniu.*stosowane', 'treatment_rules'),
        (r'Kryteria\s+kwalifikacji', 'eligibility'),
        (r'Og√≥lne\s+kryteria', 'eligibility_general'),
        (r'Szczeg√≥≈Çowe\s+kryteria', 'eligibility_detailed'),
        (r'Okre≈õlenie\s+czasu\s+leczenia', 'treatment_duration'),
        (r'Kryteria\s+wy≈ÇƒÖczenia', 'discontinuation_criteria')
    ]

    lines = re.split(r'\.\s+(?=[A-Z])', text)  # podzia≈Ç po kropkach przed du≈ºƒÖ literƒÖ
    full_text = ' '.join(lines)

    for pattern, key in patterns:
        match = re.search(pattern, full_text, re.I)
        if match:
            # Znajd≈∫ koniec sekcji (nastƒôpny nag≈Ç√≥wek lub koniec)
            next_patterns = [p for p, _ in patterns if p != pattern]
            next_match = None
            for p in next_patterns:
                m = re.search(p, full_text[match.end():], re.I)
                if m:
                    next_match = m
                    break
            end = match.end() + next_match.start() if next_match else len(full_text)
            sections[key] = full_text[match.end():end].strip()

    # Ekstrakcja lek√≥w
    def extract_drugs(text_chunk):
        # Szukaj po nazwach lek√≥w
        drugs = []
        known_drugs = ['aflibercept', 'pembrolizumab', 'niwolumab', 'ipilimumab', 
                      'triflurydyna', 'typiracyl', 'frukwintynib', 'bewacyzumab']
        for drug in known_drugs:
            if drug.lower() in text_chunk.lower():
                drugs.append(drug)
        return list(set(drugs))

    # Budowa JSON
    result = {
        "program_name": "Leczenie zaawansowanego raka jelita grubego",
        "diagnosis": ["Zaawansowany rak jelita grubego (IV stopie≈Ñ)"],
        "age_requirements": ["Wiek 18 lat i powy≈ºej"],
        "eligibility_general": re.findall(r'‚Ä¢\s+(.*?)\.', sections.get('eligibility_general', '')) or 
                               [l.strip() for l in re.split(r';|\n', sections.get('eligibility_general', '')) if len(l.strip()) > 10],
        "eligibility_detailed": [sections.get('eligibility_detailed', '')],
        "financed_substances": {
            "chemotherapy_targeted": extract_drugs(sections.get('chemotherapy_targeted', '')),
            "immunotherapy": extract_drugs(sections.get('immunotherapy', ''))
        },
        "treatment_rules": sections.get('treatment_rules', ''),
        "treatment_duration": sections.get('treatment_duration', ''),
        "discontinuation_criteria": [l.strip() for l in re.split(r';|\n', sections.get('discontinuation_criteria', '')) if len(l.strip()) > 10]
    }

    return result

def parse_medical_guidelines(text: str) -> dict:
    """
    Parsuje tekst wytycznych medycznych, wyodrƒôbniajƒÖc kluczowe sekcje,
    takie jak finansowane leki, kryteria kwalifikacji i wy≈ÇƒÖczenia.

    Args:
        text (str): Surowy tekst z dokumentu.

    Returns:
        dict: S≈Çownik zawierajƒÖcy ustrukturyzowane dane.
    """
    # Wstƒôpne czyszczenie tekstu
    text = re.sub(r'\[.*?\]\(http.*?\)', '', text)  # Usuniƒôcie link√≥w markdown
    text = re.sub(r'(\n\s*){2,}', '\n\n', text)  # Normalizacja pustych linii

    # Struktura wyj≈õciowa
    output = {
        "finansowane_substancje": {},
        "zasady_stosowania": {},
        "kryteria_kwalifikacji": {"ogolne": [], "szczegolowe": []},
        "czas_leczenia": "",
        "kryteria_wylaczenia": []
    }

    # Wyra≈ºenia regularne do identyfikacji g≈Ç√≥wnych sekcji
    patterns = {
        "chemioterapia": r'I\.\s+w\s+zakresie\s+chemioterapii\s+i\s+leczenia\s+celowanego:(.*?)(?=II\.)',
        "immunoterapia": r'II\.\s+w\s+zakresie\s+immunoterapii:(.*?)(?=W\s+leczeniu)',
        "zasady_stosowania": r'W\s+leczeniu\s+zaawansowanego\s+raka\s+jelita\s+grubego\s+stosowane\s+sƒÖ:(.*?)(?=Kryteria\s+kwalifikacji)',
        "kryteria_ogolne": r'Og√≥lne\s+kryteria\s+kwalifikacji(.*?)(?=Szczeg√≥≈Çowe\s+kryteria|Ponadto\s+do\s+programu)',
        "kryteria_szczegolowe": r'Szczeg√≥≈Çowe\s+kryteria\s+kwalifikacji\s+do\s+terapii(.*?)(?=Okre≈õlenie\s+czasu\s+leczenia)',
        "czas_leczenia": r'Okre≈õlenie\s+czasu\s+leczenia(.*?)(?=Kryteria\s+wy≈ÇƒÖczenia)',
        "kryteria_wylaczenia": r'Kryteria\s+wy≈ÇƒÖczenia\s+z\s+programu(.*?)$'
    }

    # --- 1. Ekstrakcja list lek√≥w ---
    if match := re.search(patterns["chemioterapia"], text, re.S):
        drugs = [line.strip('; \n') for line in match.group(1).strip().split('\n') if line.strip()]
        output["finansowane_substancje"]["chemioterapia_i_leczenie_celowane"] = drugs
    
    if match := re.search(patterns["immunoterapia"], text, re.S):
        drugs = [line.strip('; \n.') for line in match.group(1).strip().split('\n') if line.strip()]
        output["finansowane_substancje"]["immunoterapia"] = drugs

    # --- 2. Ekstrakcja zasad stosowania ---
    if match := re.search(patterns["zasady_stosowania"], text, re.S):
        content = match.group(1).strip()
        # Lista lek√≥w kluczowych do podzia≈Çu tekstu
        drug_names = ["pembrolizumab", "aflibercept", "niwolumab w skojarzeniu z ipilimumabem", "triflurydyna z typiracylem", "frukwintynib"]
        # Sortowanie od najd≈Çu≈ºszego do najkr√≥tszego, aby uniknƒÖƒá b≈Çƒôdnego dopasowania
        sorted_drug_names = sorted(drug_names, key=len, reverse=True)
        # Dynamiczne tworzenie wzorca do podzia≈Çu
        split_pattern = f"({'|'.join(map(re.escape, sorted_drug_names))})"
        
        parts = re.split(split_pattern, content, flags=re.IGNORECASE)
        # ≈ÅƒÖczenie nazwy leku z jego opisem
        i = 1
        while i < len(parts) - 1:
            drug_name = parts[i].strip()
            description = parts[i+1].strip()
            output["zasady_stosowania"][drug_name.lower()] = description
            i += 2

    # --- 3. Ekstrakcja kryteri√≥w ---
    def extract_list_items(content):
        # Dzieli tekst na punkty listy, ignorujƒÖc puste linie
        return [item.strip('; ') for item in content.strip().split('\n') if item.strip() and len(item.strip()) > 3]

    if match := re.search(patterns["kryteria_ogolne"], text, re.S):
        output["kryteria_kwalifikacji"]["ogolne"] = extract_list_items(match.group(1))

    if match := re.search(patterns["kryteria_szczegolowe"], text, re.S):
        output["kryteria_kwalifikacji"]["szczegolowe"] = extract_list_items(match.group(1))
        
    if match := re.search(patterns["kryteria_wylaczenia"], text, re.S):
        output["kryteria_wylaczenia"] = extract_list_items(match.group(1))

    # --- 4. Czas leczenia ---
    if match := re.search(patterns["czas_leczenia"], text, re.S):
        output["czas_leczenia"] = match.group(1).strip()

    return output


def detect_headers(text: str) -> List[str]:
    """
    Wyszukuje potencjalne nag≈Ç√≥wki:
    - linie pisane w ca≈Ço≈õci wielkimi literami
    - linie ko≈ÑczƒÖce siƒô dwukropkiem
    """
    lines = text.splitlines()
    headers = []
    for line in lines:
        t = line.strip()
        if not t: 
            continue
        if t.isupper() or t.endswith(':'):
            headers.append(re.escape(t))
    return headers

def split_by_headers(text: str) -> Dict[str, str]:
    """
    Dzieli tekst na sekcje wed≈Çug wykrytych nag≈Ç√≥wk√≥w.
    Zwraca mapƒô nag≈Ç√≥wek ‚Üí zawarto≈õƒá.
    """
    headers = detect_headers(text)
    if not headers:
        return {'CA≈ÅY_DOKUMENT': text.strip()}
    pattern = r'^(?:' + '|'.join(headers) + r')\s*$'
    parts = re.split(pattern, text, flags=re.MULTILINE)
    # findall to zachowanie kolejno≈õci nag≈Ç√≥wk√≥w
    found = re.findall(pattern, text, flags=re.MULTILINE)
    sections = {}
    for idx, hdr in enumerate(found):
        body = parts[idx+1].strip()
        sections[hdr.strip()] = body
    # ostatnia czƒô≈õƒá bez nag≈Ç√≥wka na ko≈Ñcu
    tail = parts[-1].strip()
    if tail:
        sections.setdefault('BEZ_NAG≈Å√ìWKA', tail)
    return sections

def extract_points(text: str) -> List[str]:
    """
    Ekstrakcja punkt√≥w listy:
    - po ≈õrednikach
    - punktach list ('-', '*', '+') na poczƒÖtku linii
    - numeracji '1.', 'a)', '1)'
    """
    # zastƒÖp nowe linie spacjami
    norm = re.sub(r'\s*\n\s*', ' ', text)
    raw = re.split(r';\s*|\s*[-*+]\s*|\s*\d+\.\s*|\s*[a-z]\)\s*', norm)
    return [it.strip() for it in raw if it.strip()]

def extract_schedules(text: str) -> List[Tuple[str, List[str]]]:
    """
    Szuka fragment√≥w harmonogramu:
    - wzorzec czasu: 'w dniu', 'w X tygodniu', 'co X tygodni'
    - oddziela nag≈Ç√≥wek czasu od listy punkt√≥w
    """
    # znajd≈∫ wszystkie propozycje krok√≥w czasowych
    times = re.findall(r'(w dniu[^:;]+|w\s*\d+[, \d]*\s*tygodn[iu]|co\s*\d+\s*tygodn[iu])', text, flags=re.IGNORECASE)
    result = []
    for tm in times:
        # podzia≈Ç: nag≈Ç√≥wek czasowy + reszta do nastƒôpnego czasu
        parts = re.split(re.escape(tm), text, flags=re.IGNORECASE, maxsplit=1)
        if len(parts) < 2:
            continue
        after = parts[1]
        # listƒô ko≈Ñczymy przy kolejnym czasie lub ko≈Ñcu
        next_time = re.search(r'(w dniu[^:;]+|w\s*\d+[, \d]*\s*tygodn[iu]|co\s*\d+\s*tygodn[iu])', after, flags=re.IGNORECASE)
        segment = after if not next_time else after[:next_time.start()]
        items = extract_points(segment)
        result.append((tm.strip(), items))
    return result

def parse_document2(text: str) -> Dict[str, object]:
    """
    Zwraca strukturƒô:
    {
      'TYTU≈Å_SEKCJI': ['punkt1','punkt2',‚Ä¶],
      'HARMONOGRAM': [('w dniu...', ['pt1', ‚Ä¶]), ...],
      ...
    }
    """
    sections = split_by_headers(text)
    output: Dict[str, object] = {}
    for hdr, body in sections.items():
        pts = extract_points(body)
        if any(re.match(r'(w dniu|w\s*\d+|co\s*\d+)', s, re.IGNORECASE) for s in body.split()):
            # podejrzenie harmonogramu
            sched = extract_schedules(body)
            output[f'Harmonogram ‚Äî {hdr}'] = sched
        else:
            output[hdr] = pts
    return output

def split_into_sections(text: str) -> Dict[str, str]:
    """
    Dzieli tekst na sekcje, zak≈ÇadajƒÖc ≈ºe nag≈Ç√≥wki to ca≈Çe linie wielkimi literami
    lub linie ko≈ÑczƒÖce siƒô dwukropkiem.
    """
    # Znajd≈∫ wszystkie potencjalne nag≈Ç√≥wki
    headers = re.findall(r'^(?:[A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª ]{5,}|.*?:)\s*$', text, flags=re.MULTILINE)
    
    # Je≈õli brak nag≈Ç√≥wk√≥w, ca≈Ço≈õƒá jako jedna sekcja
    if not headers:
        return {'CA≈ÅY_DOKUMENT': text.strip()}
    
    # Buduj mapƒô nag≈Ç√≥wek ‚Üí zawarto≈õƒá
    sections = {}
    # Stw√≥rz wzorzec ≈ÇƒÖczƒÖcy kolejne nag≈Ç√≥wki
    pattern = r'^(?P<header>' + '|'.join(map(re.escape, headers)) + r')\s*$'
    parts = re.split(pattern, text, flags=re.MULTILINE)
    # parts = [pusty, nag≈Ç1, zaw1, nag≈Ç2, zaw2, ..., ostatnia]
    for i in range(1, len(parts), 2):
        hdr = parts[i].strip()
        body = parts[i+1].strip()
        sections[hdr] = body
    return sections

def parse_section_items(section_text: str) -> List[str]:
    """
    Rozdziela akapit sekcji na listƒô punkt√≥w:
    - po ≈õrednikach
    - po wypunktowaniach (-, *) na poczƒÖtku linii
    - po numeracji (1., a))
    """
    # Usu≈Ñ zbƒôdne nowe linie w obrƒôbie punkt√≥w
    normalized = re.sub(r'\s*\n\s*', ' ', section_text)
    # Podziel po ≈õrednikach lub punktach listy
    items = re.split(r';\s+|\n[-*]\s+|\d+\.\s+|[a-z]\)\s+', normalized)
    return [it.strip() for it in items if it.strip()]

def parse_document(text: str) -> Dict[str, List[str]]:
    """
    Zwraca s≈Çownik nag≈Ç√≥wek ‚Üí lista punkt√≥w z sekcji.
    """
    sections = split_into_sections(text)
    structured = {}
    for hdr, body in sections.items():
        items = parse_section_items(body)
        structured[hdr] = items
    return structured

def extract_title(doc):
    """Extract the title from the document"""
    # Look for the title pattern in the document
    for paragraph in doc.paragraphs:
        text = paragraph.text.strip()
        if "LECZENIE CHORYCH " in text and "ICD-10" in text:
            return text
    return None

def extract_table_data(doc):
    """Extract specific columns from tables"""
    extracted_data = {
        '≈öWIADCZENIOBIORCY': [],
        'SCHEMAT DAWKOWANIA LEK√ìW W PROGRAMIE': [],
        'BADANIA DIAGNOSTYCZNE WYKONYWANE W RAMACH PROGRAMU': []
    }

    for table in doc.tables:
        # Check if this is the main table by looking for header patterns
        header_found = False
        for row in table.rows:
            for cell in row.cells:
                if '≈öWIADCZENIOBIORCY' in cell.text:
                    header_found = True
                    break
            if header_found:
                break

        if header_found:
            # Extract data from the table
            rows = list(table.rows)
            if len(rows) > 1:
                # Find column indices
                header_row = rows[1]
                # if header_row.text=='ZAKRES ≈öWIADCZENIA GWARANTOWANEGO' :
                #     header_row = rows[1] # Debugging line to see header row contents
                col_indices = {}

                for i, cell in enumerate(header_row.cells):
                    print(cell.text)  # Debugging line to see cell contents
                    cell_text = cell.text.strip()
                    if '≈öWIADCZENIOBIORCY' in cell_text:
                        col_indices['≈öWIADCZENIOBIORCY'] = i
                    elif 'SCHEMAT DAWKOWANIA' in cell_text:
                        col_indices['SCHEMAT DAWKOWANIA LEK√ìW W PROGRAMIE'] = i
                    elif 'BADANIA DIAGNOSTYCZNE' in cell_text:
                        col_indices['BADANIA DIAGNOSTYCZNE WYKONYWANE W RAMACH PROGRAMU'] = i

                # Extract data rows
                for row in rows[1:]:
                    for col_name, col_idx in col_indices.items():
                        if col_idx < len(row.cells):
                            extracted_data[col_name].append(row.cells[col_idx].text.strip())
                        else:
                            extracted_data[col_name].append("")

    return extracted_data

def process_docx_file(file_path):
    """Main function to process DOCX file"""
    try:
        doc = Document(file_path)

        # Extract title
        title = extract_title(doc)

        # Extract table data
        table_data = extract_table_data(doc)

        return title, table_data
    except Exception as e:
        return None, f"Error processing file: {str(e)}"

def main():
    st.set_page_config(layout="wide")
    st.title("Program Lekowy - Analiza Dokument√≥w DOCX")

    st.header("Wczytywanie pliku DOCX")

    docs_folder = Path("doks")

    if not docs_folder.exists():
        st.error(f"Folder 'doks/' nie istnieje.")
        return

    # Pobierz listƒô plik√≥w .docx
    docx_files = list(docs_folder.glob("*.docx"))

    # Selectbox do wyboru pliku
    selected_file_name = st.selectbox(
        "Wybierz plik DOCX z folderu 'doks/':",
        options=[f.name for f in docx_files],
        index=0
    )

    uploaded_file = None
    selected_file_path = docs_folder / selected_file_name
    uploaded_file = selected_file_path

    if uploaded_file is not None:
        # Save uploaded file temporarily
        # with open("temp_file.docx", "wb") as f:
        #     f.write(uploaded_file.getbuffer())

        # Process the file
        title, table_data = process_docx_file(selected_file_path)

        if title:
            st.header("Tytu≈Ç programu:")
            st.write(f"**{title}**")
        else:
            st.error("Nie mo≈ºna znale≈∫ƒá tytu≈Çu programu w dokumencie.")

        if isinstance(table_data, dict) and any(table_data.values()):
            st.header("Dane z tabeli:")

            # Create DataFrame
            max_length = max(len(v) for v in table_data.values() if v)

            # Pad shorter lists with empty strings
            for key in table_data:
                while len(table_data[key]) < max_length:
                    table_data[key].append("")

            df = pd.DataFrame(table_data)

            # Display as expandable sections
            #col1, col2, col3 = st.columns(3)
            col1 = st.container()
            col2 = st.container()
            col3 = st.container()

            with col1:
                st.subheader("≈öWIADCZENIOBIORCY")
                for i, content in enumerate(df['≈öWIADCZENIOBIORCY']):
                    if content.strip():
                        with st.expander(f"Sekcja {i+1}"):
                            #st.write(content)
                            data = parse_document(content)
                            string_wczytany = ""
                            for header, points in data.items():
                                st.write(f'## {header}')
                                string_wczytany += f'## {header}\n'
                                for idx, pt in enumerate(points, 1):
                                    st.write(f'{idx}. {pt}')
                                    string_wczytany += f'{idx}. {pt}\n'
                                st.write('---')
                                string_wczytany += '---\n'
                            
                            st.subheader("test:")
                            temp = parse_medical_program_v2(content)
                            st.json(temp)
                            html = generate_medical_tree_html_universal(json.dumps(temp))
                            with st.expander("Poka≈º wygenerowany HTML"):
                                st.markdown(html, unsafe_allow_html=True)
                            if content and string_wczytany:
                                st.subheader("R√≥≈ºnice:")
                                # lines1 = content.splitlines()
                                # lines2 = string_wczytany.splitlines()
                                # if len(lines1) < len(lines2):
                                #     lines1.insert(0, "")
                                # elif len(lines2) < len(lines1):
                                #     lines2.insert(0, "")

                                # text1_aligned = "\n".join(lines1)
                                # text2_aligned = "\n".join(lines2)
                                # U≈ºycie gotowego komponentu diff_viewer
                                diff_viewer(content, string_wczytany, split_view=True)

                                # Dodatkowe statystyki
                                similarity = difflib.SequenceMatcher(None, content, string_wczytany).ratio() 
                                st.metric("Podobie≈Ñstwo", f"{similarity:.1%}")

            with col2:
                st.subheader("SCHEMAT DAWKOWANIA LEK√ìW W PROGRAMIE")
                for i, content in enumerate(df['SCHEMAT DAWKOWANIA LEK√ìW W PROGRAMIE']):
                    if content.strip():
                        with st.expander(f"Dawkowanie {i+1}"):
                            st.write(content)

            with col3:
                st.subheader("BADANIA DIAGNOSTYCZNE WYKONYWANE W RAMACH PROGRAMU")
                for i, content in enumerate(df['BADANIA DIAGNOSTYCZNE WYKONYWANE W RAMACH PROGRAMU']):
                    if content.strip():
                        with st.expander(f"Badania {i+1}"):
                            st.write(content)
                            parsed = parse_document2(content)
                            for section, content in parsed.items():
                                st.write(f'## {section}')
                                if isinstance(content, list) and content and isinstance(content[0], tuple):
                                    # to harmonogram
                                    for time_label, items in content:
                                        st.write(f'- **{time_label}**:')
                                        for it in items:
                                            st.write(f'  - {it}')
                                else:
                                    for item in content if isinstance(content, list) else []:
                                        st.write(f'- {item}')
                                st.write('---')

            # Display full table
            st.header("Pe≈Çna tabela:")
            st.dataframe(df, use_container_width=True)

            # Download option
            csv = df.to_csv(index=False)
            st.download_button(
                label="Pobierz dane jako CSV",
                data=csv,
                file_name='program_lekowy_dane.csv',
                mime='text/csv'
            )
        else:
            st.warning("Nie znaleziono danych tabeli lub wystƒÖpi≈Ç b≈ÇƒÖd podczas ekstrakacji.")
            if isinstance(table_data, str):
                st.error(table_data)

if __name__ == "__main__":
    main()
